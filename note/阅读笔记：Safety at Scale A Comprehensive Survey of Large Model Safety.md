[[2025-A Comprehensive Survey of Large Model Safety.pdf]]

# Abstract

# Introduction

**研究的model：**
1. Vision Foundation Models (VFM)
2. (Large Language Models (LLM)
3. Vision-Language Pre-Training Models (VLP)
4. Vision-Language Models (VLM)
5. image/video generation diffusion models (DM)
6. Agent

攻击类型：
1. adversial
2. backdoor
3. data poisoning
4. jailbreak
5. prompt injection
6. energy-latency
7. membership inference
8. model extraction
9. data extraction
10. agent attacks

![[Pasted image 20250702200816.png]]
# VFM safety

## per-trained Vision Transformers (ViTs)

1. Adversarial Attacks
	1. white-box attacks
		1. patch attacks
		2. position embedding attacks
		3. attention attacks
	2. black-box attacks
		1. transfer-based attacks
		2. query-based attacks
2. Adbversarial Defenses
## Segment Anything Model (SAM)

